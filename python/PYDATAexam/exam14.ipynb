{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연관규칙 ,연관성분석 (association analaysis) - 비지도 학습\n",
    "### 대량의 데이터에 숨겨진 항목간의 연관규칙을 찾아내는 기법으로서  다른말로 장바구니 분석(market basket analysis)이라고도 한다.\n",
    "### 실제 연관성 분석은 월마트, 아마존 등 여러기업에서 다양한 마케팅 활동에 활용하고 있으며 더 나아가 사회 네트워크 분석에도 활용할 수 있다.\n",
    "### 빈발패턴 : 주어진 데이터 셋에서 빈발하게 발생하는 패턴을 찾아내는 기법\n",
    "### 연관규칙 : 빈발패턴들 간의 연관성을 규칙으로 찾아내는 기법\n",
    "### 장점\n",
    "- 대규모 거래 데이터에 대해 작업을 할 수 있다.\n",
    "- 이해하기 쉬운 규칙을 생성해준다.\n",
    "- 데이터마이닝과 데이터 베이스에서 예상치 못한 지식을 발굴하는데 유용하다.\n",
    "\n",
    "### 단점\n",
    "- 작은 데이터셋에는 그다지 유용하지 않다\n",
    "- 진정한 통찰력과 상식을 분리하기 위한 노력이 필요하다.\n",
    " \n",
    "### 지지도(support) - 규칙의 중요성 - 필요조건\n",
    "전체 거래중 연관성 규칙을 구성하는 항목들이 포함된 거래의 비율\n",
    "\n",
    "support = 항목에 대한 거래수 / 전체 거래수  또는  A,B가 동시에 포함된 거래수 / 전체 거래수\n",
    "\n",
    "### 신뢰도(confidence) - 규칙의 신뢰성 - 충분조건\n",
    "항목 A를 포함하는 거래 중에서 항목 A와 항목 B가 같이 포함될 확률\n",
    "연관성의 정도\n",
    "             \n",
    "confidence = 조건과 결과 항목을 동시에 포함하는 거래수 / 조건항목을 포함한 거래수  또는 A,B가 동시에 포함된 거래수 / A를 포함하는 거래수\n",
    "                          \n",
    "### 향상도(lift)\n",
    "- 지지도와 신뢰도를 동시에 고려한다.\n",
    "- 향상도 값이 1인 경우 조건과 결과는 우연에 의한 관계라고 보며 1보다 클수록 우연이 아닌 의미있는 연관성을 가진 규칙이라고 해석한다.\n",
    "- '높은 상관 관계를 가진' 것들 만으로 추려내기 위한 지표\n",
    "- 어떤 연관 규칙이 정말 연관성이 있는지 판단하려면 향상도가 1보다 큰 수치로 나타나야 함.\n",
    "- 향상도 = A,B동시구매 비율 / A구매 비율*B구매 비율\n",
    "\n",
    "lift(A -> B) = support(A -> B) / support(A) * support(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빈발항목중에서 후보집합을 선정하는 기준으로 지지도(Support) 를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelationRecord(items=frozenset({'Cold Drink'}), support=0.6, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Cold Drink'}), confidence=0.6, lift=1.0)]), RelationRecord(items=frozenset({'Eggs'}), support=0.6, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Eggs'}), confidence=0.6, lift=1.0)]), RelationRecord(items=frozenset({'Milk'}), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Milk'}), confidence=0.4, lift=1.0)]), RelationRecord(items=frozenset({'Tea'}), support=0.6, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Tea'}), confidence=0.6, lift=1.0)]), RelationRecord(items=frozenset({'Eggs', 'Cold Drink'}), support=0.6, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Cold Drink', 'Eggs'}), confidence=0.6, lift=1.0), OrderedStatistic(items_base=frozenset({'Cold Drink'}), items_add=frozenset({'Eggs'}), confidence=1.0, lift=1.6666666666666667), OrderedStatistic(items_base=frozenset({'Eggs'}), items_add=frozenset({'Cold Drink'}), confidence=1.0, lift=1.6666666666666667)]), RelationRecord(items=frozenset({'Tea', 'Cold Drink'}), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Tea', 'Cold Drink'}), confidence=0.4, lift=1.0), OrderedStatistic(items_base=frozenset({'Cold Drink'}), items_add=frozenset({'Tea'}), confidence=0.6666666666666667, lift=1.1111111111111114), OrderedStatistic(items_base=frozenset({'Tea'}), items_add=frozenset({'Cold Drink'}), confidence=0.6666666666666667, lift=1.1111111111111114)]), RelationRecord(items=frozenset({'Tea', 'Eggs'}), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Tea', 'Eggs'}), confidence=0.4, lift=1.0), OrderedStatistic(items_base=frozenset({'Eggs'}), items_add=frozenset({'Tea'}), confidence=0.6666666666666667, lift=1.1111111111111114), OrderedStatistic(items_base=frozenset({'Tea'}), items_add=frozenset({'Eggs'}), confidence=0.6666666666666667, lift=1.1111111111111114)]), RelationRecord(items=frozenset({'Tea', 'Milk'}), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Tea', 'Milk'}), confidence=0.4, lift=1.0), OrderedStatistic(items_base=frozenset({'Milk'}), items_add=frozenset({'Tea'}), confidence=1.0, lift=1.6666666666666667), OrderedStatistic(items_base=frozenset({'Tea'}), items_add=frozenset({'Milk'}), confidence=0.6666666666666667, lift=1.6666666666666667)]), RelationRecord(items=frozenset({'Tea', 'Eggs', 'Cold Drink'}), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Tea', 'Cold Drink', 'Eggs'}), confidence=0.4, lift=1.0), OrderedStatistic(items_base=frozenset({'Cold Drink'}), items_add=frozenset({'Tea', 'Eggs'}), confidence=0.6666666666666667, lift=1.6666666666666667), OrderedStatistic(items_base=frozenset({'Eggs'}), items_add=frozenset({'Tea', 'Cold Drink'}), confidence=0.6666666666666667, lift=1.6666666666666667), OrderedStatistic(items_base=frozenset({'Tea'}), items_add=frozenset({'Cold Drink', 'Eggs'}), confidence=0.6666666666666667, lift=1.1111111111111114), OrderedStatistic(items_base=frozenset({'Eggs', 'Cold Drink'}), items_add=frozenset({'Tea'}), confidence=0.6666666666666667, lift=1.1111111111111114), OrderedStatistic(items_base=frozenset({'Tea', 'Cold Drink'}), items_add=frozenset({'Eggs'}), confidence=1.0, lift=1.6666666666666667), OrderedStatistic(items_base=frozenset({'Tea', 'Eggs'}), items_add=frozenset({'Cold Drink'}), confidence=1.0, lift=1.6666666666666667)])]\n"
     ]
    }
   ],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "baskets = [\n",
    "    ['Milk', 'Tea', 'Cake'],\n",
    "    ['Eggs', 'Tea', 'Cold Drink'],\n",
    "    ['Milk', 'Eggs', 'Tea', 'Cold Drink'],\n",
    "    ['Eggs', 'Cold Drink'],\n",
    "    ['Juice']\n",
    "]\n",
    "association_result = list(apriori(baskets, min_support=0.4))\n",
    "print(association_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Cold Drink</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tea</td>\n",
       "      <td>Cold Drink</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tea</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tea</td>\n",
       "      <td>Milk</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source      target  support\n",
       "0   Eggs  Cold Drink      0.6\n",
       "1    Tea  Cold Drink      0.4\n",
       "2    Tea        Eggs      0.4\n",
       "3    Tea        Milk      0.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['source', 'target', 'support']\n",
    "network_df = pd.DataFrame(columns=columns)\n",
    "for result in  association_result:\n",
    "    if len(result.items) == 2:\n",
    "        items = [x for x in result.items]\n",
    "        row = [items[0], items[1], result.support]\n",
    "        series = pd.Series(row, index=network_df.columns)\n",
    "        network_df = network_df.append(series, ignore_index=True)\n",
    "network_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![edu1](images/edu1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "baskets = [\n",
    "    ['Milk', 'Tea', 'Cake'],\n",
    "    ['Eggs', 'Tea', 'Cold Drink'],\n",
    "    ['Milk', 'Eggs', 'Tea', 'Cold Drink'],\n",
    "    ['Eggs', 'Cold Drink'],\n",
    "    ['Juice']\n",
    "]\n",
    "association_result = list(apriori(baskets, min_support=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>Cold Drink</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source      target  support\n",
       "0   Eggs  Cold Drink      0.6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['source', 'target', 'support']\n",
    "network_df = pd.DataFrame(columns=columns)\n",
    "for result in  association_result:\n",
    "    if len(result.items) == 2:\n",
    "        items = [x for x in result.items]\n",
    "        row = [items[0], items[1], result.support]\n",
    "        series = pd.Series(row, index=network_df.columns)\n",
    "        network_df = network_df.append(series, ignore_index=True)\n",
    "network_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![edu1](images/edu2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data/basket.csv', 'r', encoding='utf-8') as cf:\n",
    "    transactions = [] \n",
    "    r = csv.reader(cf)\n",
    "    for row in r:\n",
    "        transactions.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' 소주', '콜라', '와인'],\n",
       " [' 소주', '오렌지주스', '콜라'],\n",
       " [' 콜라', '맥주', '와인'],\n",
       " [' 소주', '콜라', '맥주'],\n",
       " [' 오렌지주스', '와인']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T03:53:31.345626Z",
     "start_time": "2021-04-04T03:53:31.341628Z"
    }
   },
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "rules = apriori(transactions, min_support=0.1, min_confidence=0.1)  \n",
    "results = list(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T03:54:23.874491Z",
     "start_time": "2021-04-04T03:54:23.858497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lhs => rhs \t\tsupport \t\tconfidence \t\tlift\n",
      "[' 소주']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "['맥주']  =>  [' 소주'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "[' 소주']  =>  ['오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['오렌지주스']  =>  [' 소주'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "[' 소주']  =>  ['와인'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['와인']  =>  [' 소주'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "[' 소주']  =>  ['콜라'] \t\t0.6000\t\t1.0000\t\t1.6667\n",
      "['콜라']  =>  [' 소주'] \t\t0.6000\t\t1.0000\t\t1.6667\n",
      "[' 오렌지주스']  =>  ['와인'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['와인']  =>  [' 오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "[' 콜라']  =>  ['맥주'] \t\t0.2000\t\t1.0000\t\t2.5000\n",
      "['맥주']  =>  [' 콜라'] \t\t0.2000\t\t0.5000\t\t2.5000\n",
      "[' 콜라']  =>  ['와인'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['와인']  =>  [' 콜라'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['맥주']  =>  ['와인'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "['와인']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "['맥주']  =>  ['콜라'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "['콜라']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "['오렌지주스']  =>  ['콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['콜라']  =>  ['오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['와인']  =>  ['콜라'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['콜라']  =>  ['와인'] \t\t0.2000\t\t0.3333\t\t0.5556\n"
     ]
    }
   ],
   "source": [
    "print(\"lhs => rhs \\t\\tsupport \\t\\tconfidence \\t\\tlift\")\n",
    "for row in results:\n",
    "    support = row[1]\n",
    "    ordered_stat = row[2]\n",
    "    for ordered_item in ordered_stat:\n",
    "        lhs = [x for x in ordered_item[0]]\n",
    "        rhs = [x for x in ordered_item[1]]\n",
    "        confidence = ordered_item[2]\n",
    "        lift = ordered_item[3]\n",
    "        if len(lhs) == 1 and len(rhs) == 1 :\n",
    "            print(lhs, \" => \", rhs, \"\\t\\t{:>5.4f}\\t\\t{:>5.4f}\\t\\t{:>5.4f}\".format(support, confidence, lift))  #리프트가 1보다 크다는 것은 상관성이 크다, 1은 우연, 마이너스는 긍정적 관계 x라는 뜻   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T03:54:23.874491Z",
     "start_time": "2021-04-04T03:54:23.858497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lhs => rhs \t\tsupport \t\tconfidence \t\tlift\n",
      "[]  =>  [' 소주'] \t\t0.6000\t\t0.6000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 오렌지주스'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 콜라'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['맥주'] \t\t0.4000\t\t0.4000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['오렌지주스'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['와인'] \t\t0.6000\t\t0.6000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['콜라'] \t\t0.6000\t\t0.6000\t\t1.0000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '맥주'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "['맥주']  =>  [' 소주'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '오렌지주스'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['오렌지주스']  =>  [' 소주'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['와인'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['와인']  =>  [' 소주'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '콜라'] \t\t0.6000\t\t0.6000\t\t1.0000\n",
      "[' 소주']  =>  ['콜라'] \t\t0.6000\t\t1.0000\t\t1.6667\n",
      "['콜라']  =>  [' 소주'] \t\t0.6000\t\t1.0000\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 오렌지주스', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 오렌지주스']  =>  ['와인'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['와인']  =>  [' 오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['맥주', ' 콜라'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 콜라']  =>  ['맥주'] \t\t0.2000\t\t1.0000\t\t2.5000\n",
      "['맥주']  =>  [' 콜라'] \t\t0.2000\t\t0.5000\t\t2.5000\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 콜라', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 콜라']  =>  ['와인'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['와인']  =>  [' 콜라'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['맥주', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "['맥주']  =>  ['와인'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "['와인']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['콜라', '맥주'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "['맥주']  =>  ['콜라'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "['콜라']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['콜라', '오렌지주스'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "['오렌지주스']  =>  ['콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['콜라']  =>  ['오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['콜라', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "['와인']  =>  ['콜라'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['콜라']  =>  ['와인'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '맥주', '콜라'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['콜라', '맥주'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['맥주']  =>  [' 소주', '콜라'] \t\t0.2000\t\t0.5000\t\t0.8333\n",
      "['콜라']  =>  [' 소주', '맥주'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "[' 소주', '맥주']  =>  ['콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "[' 소주', '콜라']  =>  ['맥주'] \t\t0.2000\t\t0.3333\t\t0.8333\n",
      "['콜라', '맥주']  =>  [' 소주'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '오렌지주스', '콜라'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['콜라', '오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['오렌지주스']  =>  [' 소주', '콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['콜라']  =>  [' 소주', '오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "[' 소주', '오렌지주스']  =>  ['콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "[' 소주', '콜라']  =>  ['오렌지주스'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['콜라', '오렌지주스']  =>  [' 소주'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  [' 소주', '콜라', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 소주']  =>  ['콜라', '와인'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['와인']  =>  [' 소주', '콜라'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['콜라']  =>  [' 소주', '와인'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "[' 소주', '와인']  =>  ['콜라'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "[' 소주', '콜라']  =>  ['와인'] \t\t0.2000\t\t0.3333\t\t0.5556\n",
      "['콜라', '와인']  =>  [' 소주'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "-------------------------------------------------------------------------\n",
      "[]  =>  ['맥주', ' 콜라', '와인'] \t\t0.2000\t\t0.2000\t\t1.0000\n",
      "[' 콜라']  =>  ['맥주', '와인'] \t\t0.2000\t\t1.0000\t\t5.0000\n",
      "['맥주']  =>  [' 콜라', '와인'] \t\t0.2000\t\t0.5000\t\t2.5000\n",
      "['와인']  =>  ['맥주', ' 콜라'] \t\t0.2000\t\t0.3333\t\t1.6667\n",
      "['맥주', ' 콜라']  =>  ['와인'] \t\t0.2000\t\t1.0000\t\t1.6667\n",
      "['와인', ' 콜라']  =>  ['맥주'] \t\t0.2000\t\t1.0000\t\t2.5000\n",
      "['맥주', '와인']  =>  [' 콜라'] \t\t0.2000\t\t1.0000\t\t5.0000\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"lhs => rhs \\t\\tsupport \\t\\tconfidence \\t\\tlift\")\n",
    "for row in results:\n",
    "    support = row[1]\n",
    "    ordered_stat = row[2]\n",
    "    for ordered_item in ordered_stat:\n",
    "        lhs = [x for x in ordered_item[0]]\n",
    "        rhs = [x for x in ordered_item[1]]\n",
    "        confidence = ordered_item[2]\n",
    "        lift = ordered_item[3]\n",
    "        print(lhs, \" => \", rhs, \"\\t\\t{:>5.4f}\\t\\t{:>5.4f}\\t\\t{:>5.4f}\".format(support, confidence, lift)) \n",
    "    print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= [['양말','팬티','신발'],\n",
    "         ['신발','바지','팬티','셔츠'],\n",
    "         ['모자','양말','신발'],\n",
    "         ['신발','바지','팬티','장갑']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모자</th>\n",
       "      <th>바지</th>\n",
       "      <th>셔츠</th>\n",
       "      <th>신발</th>\n",
       "      <th>양말</th>\n",
       "      <th>장갑</th>\n",
       "      <th>팬티</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      모자     바지     셔츠    신발     양말     장갑     팬티\n",
       "0  False  False  False  True   True  False   True\n",
       "1  False   True   True  True  False  False   True\n",
       "2   True  False  False  True   True  False  False\n",
       "3  False   True  False  True  False   True   True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TransactionEncoder() #원핫인코더와 비슷하다\n",
    "t_a = t.fit(dataset).transform(dataset)\n",
    "print(type(t_a))\n",
    "df = pd.DataFrame(t_a, columns = t.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(바지)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(신발)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(양말)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(팬티)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(신발, 바지)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(바지, 팬티)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(신발, 양말)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(신발, 팬티)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(신발, 바지, 팬티)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support      itemsets\n",
       "0     0.50          (바지)\n",
       "1     1.00          (신발)\n",
       "2     0.50          (양말)\n",
       "3     0.75          (팬티)\n",
       "4     0.50      (신발, 바지)\n",
       "5     0.50      (바지, 팬티)\n",
       "6     0.50      (신발, 양말)\n",
       "7     0.75      (신발, 팬티)\n",
       "8     0.50  (신발, 바지, 팬티)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent = apriori(df, min_support=0.5, use_colnames=True)\n",
    "frequent #팬티와 신발을 묶음상품으로~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(신발)</td>\n",
       "      <td>(바지)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(바지)</td>\n",
       "      <td>(신발)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(바지)</td>\n",
       "      <td>(팬티)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(팬티)</td>\n",
       "      <td>(바지)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(신발)</td>\n",
       "      <td>(양말)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(양말)</td>\n",
       "      <td>(신발)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(신발)</td>\n",
       "      <td>(팬티)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(팬티)</td>\n",
       "      <td>(신발)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(신발, 바지)</td>\n",
       "      <td>(팬티)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(신발, 팬티)</td>\n",
       "      <td>(바지)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(바지, 팬티)</td>\n",
       "      <td>(신발)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(신발)</td>\n",
       "      <td>(바지, 팬티)</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(바지)</td>\n",
       "      <td>(신발, 팬티)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(팬티)</td>\n",
       "      <td>(신발, 바지)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support  support  \\\n",
       "0         (신발)        (바지)                1.00                0.50     0.50   \n",
       "1         (바지)        (신발)                0.50                1.00     0.50   \n",
       "2         (바지)        (팬티)                0.50                0.75     0.50   \n",
       "3         (팬티)        (바지)                0.75                0.50     0.50   \n",
       "4         (신발)        (양말)                1.00                0.50     0.50   \n",
       "5         (양말)        (신발)                0.50                1.00     0.50   \n",
       "6         (신발)        (팬티)                1.00                0.75     0.75   \n",
       "7         (팬티)        (신발)                0.75                1.00     0.75   \n",
       "8     (신발, 바지)        (팬티)                0.50                0.75     0.50   \n",
       "9     (신발, 팬티)        (바지)                0.75                0.50     0.50   \n",
       "10    (바지, 팬티)        (신발)                0.50                1.00     0.50   \n",
       "11        (신발)    (바지, 팬티)                1.00                0.50     0.50   \n",
       "12        (바지)    (신발, 팬티)                0.50                0.75     0.50   \n",
       "13        (팬티)    (신발, 바지)                0.75                0.50     0.50   \n",
       "\n",
       "    confidence      lift  leverage  conviction  \n",
       "0     0.500000  1.000000     0.000         1.0  \n",
       "1     1.000000  1.000000     0.000         inf  \n",
       "2     1.000000  1.333333     0.125         inf  \n",
       "3     0.666667  1.333333     0.125         1.5  \n",
       "4     0.500000  1.000000     0.000         1.0  \n",
       "5     1.000000  1.000000     0.000         inf  \n",
       "6     0.750000  1.000000     0.000         1.0  \n",
       "7     1.000000  1.000000     0.000         inf  \n",
       "8     1.000000  1.333333     0.125         inf  \n",
       "9     0.666667  1.333333     0.125         1.5  \n",
       "10    1.000000  1.000000     0.000         inf  \n",
       "11    0.500000  1.000000     0.000         1.0  \n",
       "12    1.000000  1.333333     0.125         inf  \n",
       "13    0.666667  1.333333     0.125         1.5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "association_rules(frequent, metric='confidence', min_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://patents.google.com/patent/KR101595961B1/ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트위터 API로 연관 키워드 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바로가기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [<Step1. API 호출> : 트위터 API로 데이터 가져오기](#<Step1.-API-호출>-:-트위터-API로-데이터-가져오기)\n",
    "    - [API 데이터로 데이터 프레임 생성하기]\n",
    "- [<Step2. 추출> : 키워드 추출](#<Step2.-추출>-:-키워드-추출)\n",
    "    - [텍스트 데이터 전처리]\n",
    "    - [nltk, konlpy를 이용한 키워드 추출]\n",
    "- [<Step3. 분석> : 연관 분석을 이용한 키워드 분석](#<Step3.-분석>-:-연관-분석을-이용한-키워드-분석)\n",
    "    - [연관 키워드 추출하기]\n",
    "    - [단어 빈도 추출하기]\n",
    "- [<Step4. 시각화> : 연관 키워드 네트워크 시각화](#<Step4.-시각화>-:-연관-키워드-네트워크-시각화)\n",
    "    - [연관 키워드 네트워크 시각화]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step1. API 호출> : 트위터 API로 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [API 데이터로 데이터 프레임 생성하기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 트위터 API 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# 발급 완료된 키를 {your_key} 대신 입력합니다.\n",
    "CONSUMER_KEY = \"RvnZeIl8ra88reu8fm23m0bST\"\n",
    "CONSUMER_SECRET = \"wTRylK94GK2KmhZUnqXonDaIszwAsS6VPvpSsIo6EX5GQLtzQo\"\n",
    "ACCESS_TOKEN_KEY = \"959614462004117506-dkWyZaO8Bz3ZXh73rspWfc1sQz0EnDU\"\n",
    "ACCESS_TOKEN_SECRET = \"rxDWfg7uz1yXMTDwijz0x90yWhDAnmOM15R6IgC8kmtTe\"\n",
    "\n",
    "# 개인정보 인증을 요청하는 Handler입니다.\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "# 인증 요청을 수행합니다.\n",
    "auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# twitter API를 사용하기 위한 준비입니다.\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### '코로나' 키워드 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword = \"코로나\"\n",
    "tweets = api.search(keyword)\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "    print(tweet.entities['user_mentions'])\n",
    "    print(tweet.entities['hashtags'])\n",
    "    print(tweet.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 프레임 형태로 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 크롤링된 데이터를 저장할 데이터 프레임입니다.\n",
    "columns = ['created', 'tweet_text']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# twitter API를 사용하여 ‘손흥민’이 포함된 100페이지의 트윗들을 크롤링한 뒤, ‘text’, ‘created_at’ 정보를 데이터 프레임으로 저장합니다.\n",
    "#for i in range(1,100):\n",
    "tweets = api.search(keyword)\n",
    "for tweet in tweets:\n",
    "        tweet_text = tweet.text\n",
    "        created = tweet.created_at\n",
    "        row = [created, tweet_text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df = df.append(series, ignore_index=True)\n",
    "print(\"Get data complete..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/tweet_temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step2. 추출> : 키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [텍스트 데이터 전처리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/tweet_temp.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거합니다.\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글의 정규표현식을 나타냅니다.\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘tweet_text’ 피처에 이를 적용합니다.\n",
    "df['ko_text'] = df['tweet_text'].apply(lambda x: text_cleaning(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [konlpy를 이용한 키워드 추출]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 한국어 약식 불용어사전 예시 파일입니다. 출처 - (https://www.ranks.nl/stopwords/korean)\n",
    "korean_stopwords_path = \"data/korean_stopwords.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "\n",
    "def get_nouns(x):\n",
    "    nouns_tagger = Okt()\n",
    "    nouns = nouns_tagger.nouns(x)\n",
    "    \n",
    "    # 한글자 키워드를 제거합니다.\n",
    "    nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "    \n",
    "    # 불용어를 제거합니다.\n",
    "    nouns = [noun for noun in nouns if noun not in stopwords]\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘ko_text’ 피처에 이를 적용합니다.\n",
    "df['nouns'] = df['ko_text'].apply(lambda x: get_nouns(x))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step3. 분석> : 연관 분석을 이용한 키워드 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연관 키워드 추출하기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 트위터 연관 키워드 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜잭션 데이터를 추출합니다.\n",
    "transactions = df['nouns'].tolist()\n",
    "transactions = [transaction for transaction in transactions if transaction] # 공백 문자열을 방지합니다.\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연관 분석을 수행합니다.\n",
    "results = list(apriori(transactions,\n",
    "                       min_support=0.1,\n",
    "                       min_confidence=0.2,\n",
    "                       min_lift=2,\n",
    "                       max_length=2))\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 형태로 정리합니다.\n",
    "columns = ['source', 'target', 'support']\n",
    "network_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 규칙의 조건절을 source, 결과절을 target, 지지도를 support 라는 데이터 프레임의 피처로 변환합니다.\n",
    "for result in results:\n",
    "    if len(result.items) == 2:\n",
    "        items = [x for x in result.items]\n",
    "        row = [items[0], items[1], result.support]\n",
    "        series = pd.Series(row, index=network_df.columns)\n",
    "        network_df = network_df.append(series, ignore_index=True)\n",
    "\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [단어 빈도 추출하기]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 말뭉치 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말뭉치를 추출합니다.\n",
    "tweet_corpus = \"\".join(df['ko_text'].tolist())\n",
    "print(tweet_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 명사 키워드를 추출합니다.\n",
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(tweet_corpus)\n",
    "count = Counter(nouns)\n",
    "\n",
    "# 한글자 키워드를 제거합니다.\n",
    "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
    "print(remove_char_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단어 빈도 점수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드와 키워드 빈도 점수를 ‘node’, ‘nodesize’ 라는 데이터 프레임의 피처로 생성합니다.\n",
    "node_df = pd.DataFrame(remove_char_counter.items(), columns=['node', 'nodesize'])\n",
    "node_df = node_df[node_df['nodesize'] >= 2] # 시각화의 편의를 위해 ‘nodesize’ 2 미만은 제거합니다.\n",
    "node_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Step4. 시각화> : 연관 키워드 네트워크 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [연관 키워드 네트워크 시각화]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_path = \"data/THEdog.ttf\"   #폰트파일의 위치\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# networkx 그래프 객체를 생성합니다.\n",
    "G = nx.Graph()\n",
    "\n",
    "# node_df의 키워드 빈도수를 데이터로 하여, 네트워크 그래프의 ‘노드’ 역할을 하는 원을 생성합니다.\n",
    "for index, row in node_df.iterrows():\n",
    "    G.add_node(row['node'], nodesize=row['nodesize']*5)\n",
    "    \n",
    "# network_df의 연관 분석 데이터를 기반으로, 네트워크 그래프의 ‘관계’ 역할을 하는 선을 생성합니다.\n",
    "for index, row in network_df.iterrows():\n",
    "    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n",
    "    \n",
    "# 그래프 디자인과 관련된 파라미터를 설정합니다.\n",
    "pos = nx.spring_layout(G, k=0.6, iterations=50)\n",
    "sizes = [G.nodes[node]['nodesize']*25 for node in G]\n",
    "nx.draw(G, pos=pos, node_size=sizes)\n",
    "\n",
    "nx.draw_networkx_labels(G, pos=pos, font_family=font_name, font_size=25)\n",
    "\n",
    "# 그래프를 출력합니다.\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
