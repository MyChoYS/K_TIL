{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: deck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 예제 5-1\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# deck 열의 NaN 개수 계산하기\n",
    "nan_deck = df['deck'].value_counts(dropna=False) \n",
    "print(nan_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# notnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 개수 구하기\n",
    "print(df.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dropna image](images/dropna.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-2\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# for 반복문으로 각 열의 NaN 개수 계산하기\n",
    "missing_df = df.isnull()\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts()    # 각 열의 NaN 개수 파악\n",
    "    try: \n",
    "        print(col, ': ', missing_count[True])   # NaN 값이 있으면 개수를 출력\n",
    "    except:\n",
    "        print(col, ': ', 0)                     # NaN 값이 없으면 0개 출력\n",
    "        \n",
    "# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개 중 688개의 NaN 값)\n",
    "df_thresh = df.dropna(axis=1, thresh=500)  \n",
    "print(df_thresh.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)  \n",
    "print(len(df_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-3\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값)\n",
    "print(df['age'].head(10))\n",
    "print('\\n')\n",
    "\n",
    "# age 열의 NaN값을 다른 나이 데이터의 평균으로 변경하기\n",
    "mean_age = df['age'].mean(axis=0)   # age 열의 평균 계산 (NaN 값 제외)\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# age 열의 첫 10개 데이터 출력 (5 행에 NaN 값이 평균으로 대체)\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 5-4\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embark_town'].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embark_town 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()   \n",
    "print(most_freq)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embark_town'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# embark_town 열 829행의 NaN 데이터 출력 (NaN 값이 most_freq 값으로 대체)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-5\n",
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embark_town 열의 NaN값을 바로 앞에 있는 828행의 값으로 변경하기\n",
    "df['embark_town'].fillna(method='ffill', inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-6\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],\n",
    "                  'c2':[1, 1, 1, 2, 2],\n",
    "                  'c3':[1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임 전체 행 데이터 중에서 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-7\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 중복 데이터를 갖는 데이터프레임 만들기\n",
    "df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],\n",
    "                  'c2':[1, 1, 1, 2, 2],\n",
    "                  'c3':[1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에서 중복 행을 제거\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2, c3열을 기준으로 중복 행을 제거\n",
    "df3 = df.drop_duplicates(subset=['c2', 'c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-8\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "print(df.head(3))    \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환 (mpg_to_kpl = 0.425)\n",
    "mpg_to_kpl = 1.60934 / 3.78541\n",
    "\n",
    "# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "print(df.head(3))    \n",
    "print('\\n')\n",
    "\n",
    "# kpl 열을 소수점 아래 둘째 자리에서 반올림 \n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head(3))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-9\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# 각 열의 자료형 확인\n",
    "print(df.dtypes)   \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horsepower 열의 고유값 확인\n",
    "print(df['horsepower'].unique())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락 데이터('?') 삭제 \n",
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 자료형 확인\n",
    "print(df['horsepower'].dtypes)  \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin 열의 고유값 확인\n",
    "print(df['origin'].unique())\n",
    "# 정수형 데이터를 문자형 데이터로 변환 \n",
    "df['origin'].replace({1:'USA', 2:'EU', 3:'JAPAN'}, inplace=True)\n",
    "\n",
    "# origin 열의 고유값과 자료형 확인\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes) \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin 열의 문자열 자료형을 범주형으로 변환\n",
    "df['origin'] = df['origin'].astype('category')     \n",
    "print(df['origin'].dtypes) \n",
    "\n",
    "# 범주형을 문자열로 다시 변환\n",
    "df['origin'] = df['origin'].astype('str')     \n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model year 열의 정수형을 범주형으로 변환\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category') \n",
    "print(df['model year'].sample(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    }
   ],
   "source": [
    "# 예제 5-10\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 함수로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count,bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    horsepower hp_bin\n",
      "0        130.0   보통출력\n",
      "1        165.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        150.0   보통출력\n",
      "4        140.0   보통출력\n",
      "5        198.0    고출력\n",
      "6        220.0    고출력\n",
      "7        215.0    고출력\n",
      "8        225.0    고출력\n",
      "9        190.0    고출력\n",
      "10       170.0    고출력\n",
      "11       160.0   보통출력\n",
      "12       150.0   보통출력\n",
      "13       225.0    고출력\n",
      "14        95.0    저출력\n"
     ]
    }
   ],
   "source": [
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함 \n",
    "\n",
    "# horsepower 열, hp_bin 열의 첫 15행을 출력\n",
    "print(df[['horsepower', 'hp_bin']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-11\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 으로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함\n",
    "\n",
    "# hp_bin 열의 범주형 데이터를 더미 변수로 변환\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-12\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name'] \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 으로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열\n",
    "                      bins=bin_dividers,      # 경계 값 리스트\n",
    "                      labels=bin_names,       # bin 이름\n",
    "                      include_lowest=True)    # 첫 경계값 포함\n",
    "\n",
    "# sklern 라이브러리 불러오기\n",
    "from sklearn import preprocessing    \n",
    "\n",
    "# 전처리를 위한 encoder 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder()       # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder()   # one hot encoder 생성\n",
    "\n",
    "# label encoder로 문자열 범주를 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))  \n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))\n",
    "\n",
    "# 2차원 행렬로 형태 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1) \n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "\n",
    "# 희소행렬로 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-13\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name']  \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 통계 요약정보로 최대값(max)을 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "df.horsepower = df.horsepower / abs(df.horsepower.max()) \n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-14 - 0~1 사이의 값으로 정규화\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight',\n",
    "              'acceleration','model year','origin','name']  \n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 통계 요약정보로 최대값(max)과 최소값(min)을 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-15\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 CSV 파일을 가져와서 df로 변환\n",
    "df = pd.read_csv('data/stock-data.csv')\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "\n",
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "print(type(df['new_Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정. 기존 날짜 열은 삭제\n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# 데이터 내용 및 자료형 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-16\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 날짜 형식의 문자열로 구성되는 리스트 정의\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "print(type(dates[0]))\n",
    "print('\\n')\n",
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "ts_dates = pd.to_datetime(dates)   \n",
    "print(ts_dates)\n",
    "print(type(ts_dates[0]))\n",
    "print('\\n')\n",
    "\n",
    "# Timestamp를 Period로 변환\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)\n",
    "pr_month = ts_dates.to_period(freq='M')\n",
    "print(pr_month)\n",
    "pr_year = ts_dates.to_period(freq='A')\n",
    "print(pr_year)\n",
    "print(type(pr_year[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-17\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# Timestamp의 배열 만들기 - 월 간격, 월의 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01',    # 날짜 범위의 시작\n",
    "                   end=None,                 # 날짜 범위의 끝\n",
    "                   periods=6,                # 생성할 Timestamp의 개수\n",
    "                   freq='MS',                # 시간 간격 (MS: 월의 시작일)\n",
    "                   tz='Asia/Seoul')          # 시간대(timezone)\n",
    "print(ts_ms)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01', periods=6, \n",
    "                   freq='M',              # 시간 간격 (M: 월의 마지막 날)\n",
    "                   tz='Asia/Seoul')       # 시간대(timezone)\n",
    "print(ts_me)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분기(3개월) 간격, 월의 마지막 날 기준\n",
    "ts_3m = pd.date_range('2019-01-01', periods=6, \n",
    "                   freq='3M',             # 시간 간격 (3M: 3개월)\n",
    "                   tz='Asia/Seoul')       # 시간대(timezone)\n",
    "print(ts_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-18\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# Period 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='M')                   # 기간의 길이 (M: 월)\n",
    "print(pr_m)\n",
    "print('\\n')\n",
    "\n",
    "# Period 배열 만들기 - 1시간 길이\n",
    "pr_h = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='H')                   # 기간의 길이 (H: 시간)\n",
    "print(pr_h)\n",
    "print('\\n')\n",
    "\n",
    "# Period 배열 만들기 - 2시간 길이\n",
    "pr_2h = pd.period_range(start='2019-01-01',    # 날짜 범위의 시작\n",
    "                   end=None,                   # 날짜 범위의 끝\n",
    "                   periods=3,                  # 생성할 Period 개수\n",
    "                   freq='2H')                  # 기간의 길이 (H: 시간)\n",
    "print(pr_2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-19\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 파일 읽어와서 df로 변환\n",
    "df = pd.read_csv('data/stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   #df에 새로운 열로 추가\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# dt 속성을 이용하여 new_Date 열의 년월일 정보를 년, 월, 일로 구분\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(type(df['new_Date'][0]))\n",
    "print(df['new_Date'].dt)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Timestamp를 Period로 변환하여 년월일 표기 변경하기\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# 원하는 열을 새로운 행 인덱스로 지정\n",
    "df.set_index('Date_m', inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5-20\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# read_csv() 함수로 파일 읽어와서 df로 변환\n",
    "df = pd.read_csv('data/stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])   # 새로운 열에 추가\n",
    "df.set_index('new_Date', inplace=True)        # 행 인덱스로 지정\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.index)\n",
    "print('\\n')\n",
    "\n",
    "# 날짜 인덱스를 이용하여 데이터 선택하기\n",
    "df_y = df.loc['2018']\n",
    "print(df_y.head())\n",
    "print('\\n')\n",
    "df_ym = df.loc['2018-07']    # loc 인덱서 활용\n",
    "print(df_ym)\n",
    "print('\\n')\n",
    "df_ym_cols = df.loc['2018-07-02', 'Start':'High']    # 열 범위 슬라이싱\n",
    "print(df_ym_cols)\n",
    "print('\\n')\n",
    "df_ymd = df.loc['2018-07-02']\n",
    "print(df_ymd)\n",
    "print('\\n')\n",
    "df_ymd_range = df['2018-06-25':'2018-06-20']    # 날짜 범위 지정\n",
    "print(df_ymd_range)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 간격 계산. 최근 180일 ~ 189일 사이의 값들만 선택하기\n",
    "today = pd.to_datetime('2018-12-25')            # 기준일 생성\n",
    "df['time_delta'] = today - df.index             # 날짜 차이 계산\n",
    "df.set_index('time_delta', inplace=True)        # 행 인덱스로 지정\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.to_datetime('2021-01-04')\n",
    "print(dd.year)\n",
    "print(dd.month)\n",
    "print(dd.day)\n",
    "print(dd.hour)\n",
    "print(dd.days_in_month)\n",
    "print(dd.dayofweek)\n",
    "print(dd.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.to_datetime('2021-01-10'))\n",
    "print(pd.to_datetime('20210110'))\n",
    "print(pd.to_datetime('01102021', format='%m%d%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.to_datetime('2021-01-10T13:30'))\n",
    "print(pd.to_datetime('2021-01-10 13:30'))\n",
    "print(pd.to_datetime('202101101330'))\n",
    "print(pd.to_datetime('2021-01-10 13-30', format='%Y-%m-%d %H-%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_path = \"data/THEdog.ttf\"   #폰트파일의 위치\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stock-data.csv')\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) \n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(df['Volume'])\n",
    "plt.grid()\n",
    "plt.title('주식거래량')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(df['Start'],label=\"주식시가\")\n",
    "plt.plot(df['Close'],label=\"주식종가\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('주식거래량')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(df['High'],label=\"주식최고가\")\n",
    "plt.plot(df['Low'],label=\"주식최저가\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('주식거래량')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df['2018-06-19':'2018-06-11']\n",
    "df2 = df1[['Close', 'Start', 'High', 'Low']]\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(df2)\n",
    "plt.grid()\n",
    "plt.legend(['Close', 'Start', 'High', 'Low'])\n",
    "plt.title('2018년 6월 11일~19일 주식거래량')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
